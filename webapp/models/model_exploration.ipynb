{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1d6c6bca657e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stopwords\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_status</th>\n",
       "      <th>datetime</th>\n",
       "      <th>description</th>\n",
       "      <th>edition</th>\n",
       "      <th>ics</th>\n",
       "      <th>id</th>\n",
       "      <th>number_of_pages</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>section_titles</th>\n",
       "      <th>sections</th>\n",
       "      <th>tc</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Published</td>\n",
       "      <td>2018-03-10 19:40:16</td>\n",
       "      <td>The method is applicable to carbide and binder...</td>\n",
       "      <td>Edition : 1</td>\n",
       "      <td>[77.160]</td>\n",
       "      <td>ISO 4501:1978</td>\n",
       "      <td>Number of pages : 3</td>\n",
       "      <td>https://www.iso.org/obp/ui/#!iso:std:10399:en</td>\n",
       "      <td>1978-08</td>\n",
       "      <td>[FOREWORD, 1   SCOPE]</td>\n",
       "      <td>[FOREWORD\\nISO (the International Organization...</td>\n",
       "      <td>ISO/TC 119/SC 4</td>\n",
       "      <td>Hardmetals -- Determination of titanium -- Pho...</td>\n",
       "      <td>https://www.iso.org/standard/10399.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Published</td>\n",
       "      <td>2018-03-10 19:40:24</td>\n",
       "      <td>This part presents definitions of terms, in En...</td>\n",
       "      <td>Edition : 2</td>\n",
       "      <td>[83.160.01, 01.040.83]</td>\n",
       "      <td>ISO 4223-2:1991</td>\n",
       "      <td>Number of pages : 2</td>\n",
       "      <td>https://www.iso.org/obp/ui/#!iso:std:10022:en</td>\n",
       "      <td>1991-01</td>\n",
       "      <td>[Foreword, Scope, 1   General definitions, 2  ...</td>\n",
       "      <td>[Foreword\\nISO (the International Organization...</td>\n",
       "      <td>ISO/TC 31</td>\n",
       "      <td>Definitions of some terms used in the tyre ind...</td>\n",
       "      <td>https://www.iso.org/standard/10022.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Published</td>\n",
       "      <td>2018-03-10 19:40:32</td>\n",
       "      <td>The determination is carried out in the follow...</td>\n",
       "      <td>Edition : 1</td>\n",
       "      <td>[71.100.40]</td>\n",
       "      <td>ISO 4314:1977</td>\n",
       "      <td>Number of pages : 2</td>\n",
       "      <td>https://www.iso.org/obp/ui/#!iso:std:10183:en</td>\n",
       "      <td>1977-02</td>\n",
       "      <td>[FOREWORD, 1   SCOPE AND FIELD OF APPLICATION,...</td>\n",
       "      <td>[FOREWORD\\nISO (the International Organization...</td>\n",
       "      <td>ISO/TC 91</td>\n",
       "      <td>Surface active agents -- Determination of free...</td>\n",
       "      <td>https://www.iso.org/standard/10183.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Published</td>\n",
       "      <td>2018-03-10 19:40:40</td>\n",
       "      <td></td>\n",
       "      <td>Edition : 1</td>\n",
       "      <td>[25.220.50, 67.250, 97.040.60]</td>\n",
       "      <td>ISO 4531-2:1998</td>\n",
       "      <td>Number of pages : 3</td>\n",
       "      <td>https://www.iso.org/obp/ui/#!iso:std:10443:en</td>\n",
       "      <td>1998-10</td>\n",
       "      <td>[Foreword, Introduction, 1   Scope, 2   Normat...</td>\n",
       "      <td>[Foreword\\nISO (the International Organization...</td>\n",
       "      <td>ISO/TC 107</td>\n",
       "      <td>Vitreous and porcelain enamels -- Release of l...</td>\n",
       "      <td>https://www.iso.org/standard/10443.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Published</td>\n",
       "      <td>2018-03-10 19:40:48</td>\n",
       "      <td>The water in a test portion is removed by azeo...</td>\n",
       "      <td>Edition : 2</td>\n",
       "      <td>[71.100.40]</td>\n",
       "      <td>ISO 4318:1989</td>\n",
       "      <td>Number of pages : 2</td>\n",
       "      <td>https://www.iso.org/obp/ui/#!iso:std:10189:en</td>\n",
       "      <td>1989-06</td>\n",
       "      <td>[Foreword, 1   Scope, 2   Normative references]</td>\n",
       "      <td>[Foreword\\nISO (the International Organization...</td>\n",
       "      <td>ISO/TC 91</td>\n",
       "      <td>Surface active agents and soaps -- Determinati...</td>\n",
       "      <td>https://www.iso.org/standard/10189.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  current_status            datetime  \\\n",
       "0      Published 2018-03-10 19:40:16   \n",
       "1      Published 2018-03-10 19:40:24   \n",
       "2      Published 2018-03-10 19:40:32   \n",
       "3      Published 2018-03-10 19:40:40   \n",
       "4      Published 2018-03-10 19:40:48   \n",
       "\n",
       "                                         description      edition  \\\n",
       "0  The method is applicable to carbide and binder...  Edition : 1   \n",
       "1  This part presents definitions of terms, in En...  Edition : 2   \n",
       "2  The determination is carried out in the follow...  Edition : 1   \n",
       "3                                                     Edition : 1   \n",
       "4  The water in a test portion is removed by azeo...  Edition : 2   \n",
       "\n",
       "                              ics               id      number_of_pages  \\\n",
       "0                        [77.160]    ISO 4501:1978  Number of pages : 3   \n",
       "1          [83.160.01, 01.040.83]  ISO 4223-2:1991  Number of pages : 2   \n",
       "2                     [71.100.40]    ISO 4314:1977  Number of pages : 2   \n",
       "3  [25.220.50, 67.250, 97.040.60]  ISO 4531-2:1998  Number of pages : 3   \n",
       "4                     [71.100.40]    ISO 4318:1989  Number of pages : 2   \n",
       "\n",
       "                                     preview_url publication_date  \\\n",
       "0  https://www.iso.org/obp/ui/#!iso:std:10399:en          1978-08   \n",
       "1  https://www.iso.org/obp/ui/#!iso:std:10022:en          1991-01   \n",
       "2  https://www.iso.org/obp/ui/#!iso:std:10183:en          1977-02   \n",
       "3  https://www.iso.org/obp/ui/#!iso:std:10443:en          1998-10   \n",
       "4  https://www.iso.org/obp/ui/#!iso:std:10189:en          1989-06   \n",
       "\n",
       "                                      section_titles  \\\n",
       "0                              [FOREWORD, 1   SCOPE]   \n",
       "1  [Foreword, Scope, 1   General definitions, 2  ...   \n",
       "2  [FOREWORD, 1   SCOPE AND FIELD OF APPLICATION,...   \n",
       "3  [Foreword, Introduction, 1   Scope, 2   Normat...   \n",
       "4    [Foreword, 1   Scope, 2   Normative references]   \n",
       "\n",
       "                                            sections               tc  \\\n",
       "0  [FOREWORD\\nISO (the International Organization...  ISO/TC 119/SC 4   \n",
       "1  [Foreword\\nISO (the International Organization...        ISO/TC 31   \n",
       "2  [FOREWORD\\nISO (the International Organization...        ISO/TC 91   \n",
       "3  [Foreword\\nISO (the International Organization...       ISO/TC 107   \n",
       "4  [Foreword\\nISO (the International Organization...        ISO/TC 91   \n",
       "\n",
       "                                               title  \\\n",
       "0  Hardmetals -- Determination of titanium -- Pho...   \n",
       "1  Definitions of some terms used in the tyre ind...   \n",
       "2  Surface active agents -- Determination of free...   \n",
       "3  Vitreous and porcelain enamels -- Release of l...   \n",
       "4  Surface active agents and soaps -- Determinati...   \n",
       "\n",
       "                                       url  \n",
       "0  https://www.iso.org/standard/10399.html  \n",
       "1  https://www.iso.org/standard/10022.html  \n",
       "2  https://www.iso.org/standard/10183.html  \n",
       "3  https://www.iso.org/standard/10443.html  \n",
       "4  https://www.iso.org/standard/10189.html  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#from nltk.corpus import stopwords\n",
    "df = pd.read_json(\"../standards/iso_flat.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(row):\n",
    "    \"\"\"\n",
    "    The field is the first set of numbers before the decimal in in the ics code of form ##.###,#\n",
    "    :param row, a row of a dataframe containing the field \"ics\"\n",
    "    :return field, a list of the fields the standard belongs to\n",
    "    \"\"\"\n",
    "    field = []\n",
    "    for ics in row:\n",
    "        field.append(ics.split(\".\")[0])\n",
    "    return field\n",
    "\n",
    "def get_group(row):\n",
    "    group = []\n",
    "    for ics in row:\n",
    "        group.append(ics.split(\".\")[1])\n",
    "    return group\n",
    "\n",
    "def get_subgroup(row):\n",
    "    subgroup = []\n",
    "    for ics in row:\n",
    "        try:\n",
    "            subgroup.append(ics.split(\".\")[2])\n",
    "        except IndexError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"field\"] = df[\"ics\"].apply(lambda x: get_field(x))\n",
    "df[\"group\"] = df[\"ics\"].apply(lambda x: get_group(x))\n",
    "df[\"subgroup\"] = df[\"ics\"].apply(lambda x: get_subgroup(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'35': 4512, '25': 2333, '13': 2245, '01': 1561, '83': 1465, '11': 1282, '43': 1239, '23': 1203, '77': 1053, '91': 1003, '03': 958, '17': 938, '49': 906, '59': 896, '67': 875, '75': 804, '71': 753, '37': 728, '65': 701, '21': 619, '47': 531, '53': 514, '27': 416, '97': 392, '87': 354, '81': 340, '73': 307, '07': 300, '55': 253, '85': 235, '79': 223, '93': 184, '19': 168, '61': 124, '33': 121, '31': 64, '39': 58, '29': 40, '45': 30, '95': 8})\n"
     ]
    }
   ],
   "source": [
    "#check the number of samples in each field\n",
    "import itertools, collections\n",
    "counter = collections.Counter(itertools.chain(*list(df[\"field\"])))\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Won't predict well for fields 29, 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the relevant text for predictors and clean text\n",
    "import re\n",
    "\n",
    "def get_scope(row):\n",
    "    text = \"\"\n",
    "    for item in row:\n",
    "        item = item.lower()\n",
    "        pattern = re.compile(\"scope\")\n",
    "        match = re.search(pattern, item)\n",
    "        if match:\n",
    "            text = item.replace(\"scope and field application\", \"\")\n",
    "            text = item.replace(\"scope\", \"\")\n",
    "    return text\n",
    "    \n",
    "df[\"scope\"] = df[\"sections\"].apply(lambda x: get_scope(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"scope\"] + \" \" + df[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any null fields\n",
    "any(pd.isnull(df[\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [u\"the\", u\"this\", u\"scope\", u\"international\", u\"iso\", u\"iec\", u\"requirement\",\n",
    "              u\"standard\", u\"application\", u\"specifies\"]\n",
    "#stop = set(stopwords.words('english'))\n",
    "for word in stop_words:\n",
    "    nlp.vocab[word].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(text):\n",
    "    text = text.lower()\n",
    "    parsed = nlp(text)\n",
    "    words = [token.lemma_ for token in parsed if not token.is_stop and not token.is_punct and not\n",
    "            token.like_num and not token.is_space]\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"parsed_text\"] = df[\"text\"].apply(lambda x: clean_and_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df[\"parsed_text\"][0:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the top words and their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_tfidf_series(text_list):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    values = vectorizer.fit_transform(text_list)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i in range(len(feature_names)):\n",
    "        feature_names[i] = feature_names[i].decode('latin1')\n",
    "    tfidf_series = pd.Series(values.toarray().sum(axis=0), index = feature_names).sort_values(ascending = False)\n",
    "    return list(zip(feature_names, tfidf_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_words = get_tfidf_series(df[\"parsed_text\"])\n",
    "top_50 = sorted(weighted_words, key = lambda x: x[1])[0:50]\n",
    "# top_50 = [list(t) for t in zip(*top_50)]\n",
    "# plt.barh(top_50[0], top_50[1], figsize = (8,20))\n",
    "# plt.show()\n",
    "top_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the label to be predicted (field) to a binary representation\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df[\"field\"].values)\n",
    "labels = list(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score #automatically uses stratified split for binary/multiclass data\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "\n",
    "def score_summary(clf, features, classification):\n",
    "    accuracy = cross_val_score(clf, features, classification, cv = 5, scoring = 'accuracy')\n",
    "    f1 = cross_val_score(clf, features, classification, cv = 5, scoring = 'f1')\n",
    "    precision = cross_val_score(clf, features, classification, cv = 5, scoring = 'precision')\n",
    "    recall = cross_val_score(clf, features, classification, cv = 5, scoring = 'recall')\n",
    "    print(\"accuracy: %0.2f (+/- %0.2f)\" % (accuracy.mean(), accuracy.std()*2))\n",
    "    print(\"F1 score: %0.2f (+/- %0.2f)\" % (f1.mean(), f1.std()*2))\n",
    "    print(\"precision: %0.2f (+/- %0.2f)\" % (precision.mean(), precision.std()*2))\n",
    "    print(\"recall: %0.2f (+/- %0.2f)\" % (recall.mean(), recall.std()*2))\n",
    "    return [accuracy.mean(), f1.mean(), precision.mean(), recall.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_summary(classifier, df[\"parsed_text\"], df[\"field\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
